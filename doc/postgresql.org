#+TITLE: Postgresql 

* The ~:ecm/server/postgresql~ file.

#+begin_src gerbil :tangle "../src/postgresql.ss"
  (import (prefix-in :drewc/postgresql/connect pg_)
          :drewc/postgresql/postgresql
          :std/db/dbi
          :std/db/conpool
          :gerbil/gambit/exceptions
          :ecm/server/conf
          :std/sugar
          :std/iter
          :std/text/json
          :std/srfi/1)
  (export #t)

  (def (ecm-sql-connect)
    (let (m (conf-value database: master:))
      (pg_connect db: (pgetq db: m)
                  port: (or (pgetq port: m) 5432)
                  user: (or (pgetq user: m) "ecm")
                  host: (or (pgetq host: m) "localhost"))))

  (def current-ecm-sql-connection (make-parameter #f))
  (def ecm-conpool (make-conpool ecm-sql-connect))

  (def (call-with-ecm-conpool-connection fn pool: (conpool ecm-conpool))
    (let (conn #f)
        (set! conn (conpool-get conpool))
        (try
         (parameterize ((current-ecm-sql-connection conn))
           (fn conn))
          (catch ((? (not sql-error?)) e)
            (conpool-release conpool conn)
            (set! conn #f)
            (display-exception e)
            (error (call-with-output-string (cut display-exception e <>))))
          (finally (when conn (conpool-put conpool conn))))))

  (defrules with-ecm-sql ()
    ((_ (con) body ...) (call-with-ecm-conpool-connection
                         (lambda (con) body ...)))
    ((_ () body ...) (with-ecm-sql (_) body ...)))


  (def (row->vector r) (if (vector? r) r (vector r)))
  (def (row->list r) (if (vector? r) (vector->list r) (list r)))
  (def (row->plist row keys)
    (let lp ((k (map string->keyword keys)) (r (row->list row)))
      (if (null? k) k
          (cons* (car k) (car r) (lp (cdr k) (cdr r))))))

  (def (row->alist row keys)
    (for/collect ((c (row->vector row)) (k keys)) (cons k c)))

  (def (row->json row)
    (if (not row) row
        (with-input-from-string 
            (if (vector? row) (vector-ref row 0) row)
      read-json)))


  (def query-return-types
    `((single . ,(lambda (rows _) (car rows)))
      (vectors . ,(lambda (rows _) (map row->vector rows)))
      (plists . ,(lambda (rows cols) (let (keys (map string->keyword cols))
                                  (map (cut row->plist <> cols) rows))))
      (plist . ,(lambda (rows cols)
                 (row->plist (car rows) cols)))
      (json . ,(lambda (rs _) (row->json (car rs))))))


  (def (query connection: (con #f)
              return: (ret 'identity)
              sql . args)
    (let* ((conn (or con (current-ecm-sql-connection) (ecm-sql-connect)))
           (stmt (if (string? sql) (sql-prepare conn sql)))
           (names (sql-columns stmt)))
      (try (unless (null? args)
             (apply sql-bind stmt args))
           (let (r ((if (null? names) sql-exec sql-query) stmt))
             (unless (null? names)
               (if (eq? ret 'identity) r
               ((assget ret query-return-types) r names))))
           (finally sql-finalize stmt))))



#+end_src


* HACKS

#+begin_src sql
SELECT * FROM pg_roles WHERE rolname ilike 'e%';
#+end_src

#+RESULTS:
| ALTER ROLE |          |            |               |             |             |                |              |             |               |              |           |       |
|------------+----------+------------+---------------+-------------+-------------+----------------+--------------+-------------+---------------+--------------+-----------+-------|
| rolname    | rolsuper | rolinherit | rolcreaterole | rolcreatedb | rolcanlogin | rolreplication | rolconnlimit | rolpassword | rolvaliduntil | rolbypassrls | rolconfig |   oid |
| ecm        | t        | t          | f             | f           | t           | f              |           -1 | ********    |               | f            |           | 72450 |

#+BEGIN_SRC sql
SELECT CURRENT_USER 
      , inet_server_addr()
       host -- use inet_client_addr() to get address of the remote connection
      , inet_client_addr()
      , inet_server_port() port -- use inet_client_port() to get port of the remote connection
#+END_SRC

#+RESULTS:
| current_user | host | inet_client_addr | port |
|--------------+------+------------------+------|
| maxclaims    | ::1  | ::1              | 5434 |

#+END_SRC
#+BEGIN_SRC gerbil 
  (import :std/db/dbi :std/db/postgresql)

  (def db (postgresql-connect
	   host: "athena.maxwellclaims.net"
	   port: 5433
	   user: "maxclaims"
	   passwd: "PASSWORD"))

  (sql-eval-query db "SELECT version();")


#+END_SRC

#+BEGIN_SRC shell
pg_dumpall --host cora.maxwellclaims.net --user=maxclaims --clean | psql -d postgres
#+END_SRC

* Create Master 

For ~INSTALL~'ing, and for testing purposes, we want to create a new
master database from scratch.


* Create standby or Restore Master

Since we have a [[file:postgresql/html/continuous-archiving.html][Continuous Archive]], it is simple.

** Ensure we have a basebackup and restore
# :tangle "../bin/restore-basebackup"
#+BEGIN_SRC shell :shebang "#!/bin/bash" 
  SOURCE="${BASH_SOURCE[0]}"
  while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
    DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
    SOURCE="$(readlink "$SOURCE")"
    [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
  done
  DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"

  # stop on errors
  set -e

  BASEBACKUP=/ecm/db/standby/basebackup
  ORIGIN='ecm@ecm.maxwellclaims.net:/ecm/db/standby/basebackup/'



  if [ ! -d "${BASEBACKUP}" ]; then
    echo "Cannot find ${BASEBACKUP}, try 'rsync-basebackup --datadir ${BASEBACKUP}'"
    exit 1
  fi

  if [ -z "${DATADIR}" ]; then
    echo "DATADIR is not set. try '-d' or '--datadir'";
    exit 1
  fi

#+END_SRC


** We create a [[#Cluster][Cluster]].

#+BEGIN_SRC shell
  sudo pg_createcluster --user=postgres --group=postgres \
    --socketdir=/var/run/postgresql  --datadir=\ 
    --locale=en_CA.UTF-8 --port 5542 10 ecm_test
  sudo pg_ctlcluster 10 ecm_test start
#+END_SRC





* WAL Archives
  :PROPERTIES:
  :CUSTOM_ID: WAL_archives
  :END:

'At all times, PostgreSQL maintains a write ahead log (WAL) in the
pg_wal/ subdirectory of the cluster's data directory. The log records
every change made to the database's data files. This log exists
primarily for crash-safety purposes: if the system crashes, the
database can be restored to consistency by “replaying” the log entries
made since the last checkpoint. However, the existence of the log
makes it possible to use a third strategy for backing up databases: we
can combine a file-system-level backup with backup of the WAL files.'
 -- file:postgresql/html/continuous-archiving.html

#+BEGIN_SRC sh
sudo mkdir -p /ecm/db/master/WAL
sudo chown -R postgres.postgres /ecm/db/master/WAL
#+END_SRC
# :tangle "../etc/postgresql/conf.d/archive.conf"
#+BEGIN_SRC conf 
wal_level = replica

# The WAL's are copied to /ecm/db/master/WAL
archive_mode = on
archive_command = 'test ! -f /ecm/db/master/WAL/%f && cp %p /ecm/db/master/WAL/%f'
#+END_SRC

"Also, you can force a segment switch manually with pg_switch_wal if
you want to ensure that a just-finished transaction is archived as
soon as possible. Other utility functions related to WAL management
are listed in Table 9.79." -- file:postgresql/html/functions-admin.html



* Standby Server / Streaming Replication

"Streaming replication allows a standby server to stay more up-to-date
than is possible with file-based log shipping. The standby connects to
the primary, which streams WAL records to the standby as they're
generated, without waiting for the WAL file to be filled."
  -- file:postgresql/html/warm-standby.html



** Master

There is a ~conf.d/replication-master.conf~
# :tangle "../etc/postgresql/conf.d/replication-master.conf"
#+BEGIN_SRC conf 

# To enable read-only queries on a standby server, wal_level must be set to
# "hot_standby". But you can choose "archive" if you never connect to the
# server in standby mode.
wal_level = hot_standby

# Set the maximum number of concurrent connections from the standby servers.
max_wal_senders = 5

# To prevent the primary server from removing the WAL segments required for
# the standby server before shipping them, set the minimum number of segments
# retained in the pg_xlog directory. At least wal_keep_segments should be
# larger than the number of segments generated between the beginning of
# online-backup and the startup of streaming replication. If you enable WAL
# archiving to an archive directory accessible from the standby, this may
# not be necessary.
wal_keep_segments = 32
#+END_SRC

*** Create the streaming role

#+BEGIN_SRC sql
DO $$
 -- CREATE ROLE IF NOT EXISTS  ecm_replication WITH REPLICATION LOGIN;
 BEGIN
 IF NOT EXISTS (SELECT FROM   pg_catalog.pg_roles
		  WHERE rolname = 'ecm_replication') 
  THEN CREATE ROLE ecm_replication WITH REPLICATION LOGIN;
  ELSE ALTER ROLE ecm_replication WITH REPLICATION LOGIN;
 END IF;
END $$; 
#+END_SRC

#+BEGIN_SRC sql
ALTER ROLE ecm_replication WITH PASSWORD 'Replicator, beware!';
#+END_SRC

*** Add to pg_hba.conf

#+BEGIN_SRC conf
  #Allow replication connections from localhost, by a user with the                                                        
  # replication privilege.                                                                                                  
  local   replication     all                                     peer
  host    replication     all             127.0.0.1/32            md5
  host    replication     all             ::1/128                 md5
  host    replication     all             samehost                md5
  host    replication     all             samenet                 md5
#+END_SRC

** Set up a standby server

#+BEGIN_SRC shell
  CLUSTER_NAME=slave

  sudo pg_createcluster --user=postgres --group=postgres \
     --socketdir=/var/run/postgresql \
     --locale=en_CA.UTF-8 10 $CLUSTER_NAME

  sudo cp /ecm/etc/postgresql/conf.d/* /etc/postgresql/10/$CLUSTER_NAME/conf.d/
  # sudo pg_ctlcluster 10 $CLUSTER_NAME start

  pg_lsclusters -h 10 $CLUSTER_NAME | cut -f3 -d' '
#+END_SRC




** See  https://wiki.postgresql.org/wiki/Streaming_Replication

NB: there is overlap between this section and Binary Replication Tutorial

    1. Install postgres in the primary and standby server as usual. This requires only configure, make and make install.
    2. Create the initial database cluster in the primary server as usual, using initdb.
    3. Create an user named replication with REPLICATION privileges. 

$ CREATE ROLE replication WITH REPLICATION PASSWORD 'password' LOGIN

    4. Set up connections and authentication on the primary so that the standby server can successfully connect to the replication pseudo-database on the primary. 

$ $EDITOR postgresql.conf

listen_addresses = '192.168.0.10'

$ $EDITOR pg_hba.conf

# The standby server must connect with a user that has replication privileges.
# TYPE  DATABASE        USER            ADDRESS                 METHOD
  host  replication     replication     192.168.0.20/32         md5

    5. Set up the streaming replication related parameters on the primary server. 

$ $EDITOR postgresql.conf

# To enable read-only queries on a standby server, wal_level must be set to
# "hot_standby". But you can choose "archive" if you never connect to the
# server in standby mode.
wal_level = hot_standby

# Set the maximum number of concurrent connections from the standby servers.
max_wal_senders = 5

# To prevent the primary server from removing the WAL segments required for
# the standby server before shipping them, set the minimum number of segments
# retained in the pg_xlog directory. At least wal_keep_segments should be
# larger than the number of segments generated between the beginning of
# online-backup and the startup of streaming replication. If you enable WAL
# archiving to an archive directory accessible from the standby, this may
# not be necessary.
wal_keep_segments = 32

# Enable WAL archiving on the primary to an archive directory accessible from
# the standby. If wal_keep_segments is a high enough number to retain the WAL
# segments required for the standby server, this is not necessary.
archive_mode    = on
archive_command = 'cp %p /path_to/archive/%f'

    6. Start postgres on the primary server.
    7. Make a base backup by copying the primary server's data directory to the standby server. 

        7.1. Do it with pg_(start|stop)_backup and rsync on the primary 

$ psql -c "SELECT pg_start_backup('label', true)"
$ rsync -ac ${PGDATA}/ standby:/srv/pgsql/standby/ --exclude postmaster.pid
$ psql -c "SELECT pg_stop_backup()"

        7.2. Do it with pg_basebackup on the standby 

In version 9.1+, pg_basebackup can do the dirty work of fetching the entire data directory of your PostgreSQL installation from the primary and placing it onto the standby server.

The prerequisite is that you make sure the standby's data directory is empty.

Make sure to remove any tablespace directories as well. You can find those directories with:

$ psql -c '\db'

If you keep your postgresql.conf and other config files in PGDATA, you need a backup of postgresql.conf, to restore after pg_basebackup.

After you've cleared all the directories, you can use the following command to directly stream the data from the primary onto your standby server. Run it as the database superuser, typically 'postgres', to make sure the permissions are preserved (use su, sudo or whatever other tool to make sure you're not root).

$ pg_basebackup -h 192.168.0.10 -D /srv/pgsql/standby -P -U replication --xlog-method=stream

In version 9.3+, you can also add the -R option so it creates a minimal recovery command file for step 9 below.

If you backed up postgresql.conf, now restore it.

    8. Set up replication-related parameters, connections and authentication in the standby server like the primary, so that the standby might work as a primary after failover.
    9. Enable read-only queries on the standby server. But if wal_level is archive on the primary, leave hot_standby unchanged (i.e., off). 

$ $EDITOR postgresql.conf

hot_standby = on

    10. Create a recovery command file in the standby server; the following parameters are required for streaming replication. 

$ $EDITOR recovery.conf
# Note that recovery.conf must be in $PGDATA directory.
# It should NOT be located in the same directory as postgresql.conf

# Specifies whether to start the server as a standby. In streaming replication,
# this parameter must to be set to on.
standby_mode          = 'on'

# Specifies a connection string which is used for the standby server to connect
# with the primary.
primary_conninfo      = 'host=192.168.0.10 port=5432 user=replication password=password'

# Specifies a trigger file whose presence should cause streaming replication to
# end (i.e., failover).
trigger_file = '/path_to/trigger'

# Specifies a command to load archive segments from the WAL archive. If
# wal_keep_segments is a high enough number to retain the WAL segments
# required for the standby server, this may not be necessary. But
# a large workload can cause segments to be recycled before the standby
# is fully synchronized, requiring you to start again from a new base backup.
restore_command = 'cp /path_to/archive/%f "%p"'

    11. Start postgres in the standby server. It will start streaming replication.
    12. You can calculate the replication lag by comparing the current WAL write location on the primary with the last WAL location received/replayed by the standby. They can be retrieved using pg_current_xlog_location on the primary and the pg_last_xlog_receive_location/pg_last_xlog_replay_location on the standby, respectively. 

$ psql -c "SELECT pg_current_xlog_location()" -h192.168.0.10 (primary host)
 pg_current_xlog_location 
--------------------------
 0/2000000
(1 row)

$ psql -c "select pg_last_xlog_receive_location()" -h192.168.0.20 (standby host)
 pg_last_xlog_receive_location 
-------------------------------
 0/2000000
(1 row)

$ psql -c "select pg_last_xlog_replay_location()" -h192.168.0.20 (standby host)
 pg_last_xlog_replay_location 
------------------------------
 0/2000000
(1 row)

    13. You can also check the progress of streaming replication by using ps command. 

# The displayed LSNs indicate the byte position that the standby server has
# written up to in the xlogs.
[primary] $ ps -ef | grep sender
postgres  6879  6831  0 10:31 ?        00:00:00 postgres: wal sender process postgres 127.0.0.1(44663) streaming 0/2000000

[standby] $ ps -ef | grep receiver
postgres  6878  6872  1 10:31 ?        00:00:01 postgres: wal receiver process   streaming 0/2000000

    How to do failover
        Create the trigger file in the standby after the primary fails. 
    How to stop the primary or the standby server
        Shut down it as usual (pg_ctl stop). 
    How to restart streaming replication after failover
        Repeat the operations from 6th; making a fresh backup, some configurations and starting the original primary as the standby. The primary server doesn't need to be stopped during these operations. 
    How to restart streaming replication after the standby fails
        Restart postgres in the standby server after eliminating the cause of failure. 
    How to disconnect the standby from the primary
        Create the trigger file in the standby while the primary is running. Then the standby would be brought up. 
    How to re-synchronize the stand-alone standby after isolation
        Shut down the standby as usual. And repeat the operations from 6th. 
    If you have more than one slave, promoting one will break the other(s). Update their recovery.conf settings to point to the new master, set recovery_target_timeline to 'latest', scp/rsync the pg_xlog directory, and restart the slave. 

* Cluster 
  :PROPERTIES:
  :CUSTOM_ID: Cluster
  :END:


# :tangle "../bin/pg_ecm-createcluster"
#+BEGIN_SRC shell :shebang "#!/usr/bin/env bash" 

  sudo pg_createcluster --user=postgres --group=postgres \
    --socketdir=/var/run/postgresql \
    --locale=en_CA.UTF-8 --port 5442 10 ecm_test
  sudo pg_ctlcluster 10 ecm_dev start
#+END_SRC

** man pg_createcluster

#+BEGIN_SRC shell :results verbatim
man pg_createcluster
#+END_SRC

#+begin_example
PG_CREATECLUSTER(1)    Debian PostgreSQL infrastructure    PG_CREATECLUSTER(1)

NAME
       pg_createcluster - create a new PostgreSQL cluster

SYNOPSIS
       pg_createcluster [options] version name [-- initdb options]

DESCRIPTION
       pg_createcluster creates a new PostgreSQL server cluster (i. e. a
       collection of databases served by a postgres(1) instance) and
       integrates it into the multi-version/multi-cluster architecture of the
       postgresql-common package.

       Every cluster is uniquely identified by its version and name. The name
       can be arbitrary. The default cluster that is created on installation
       of a server package is main. However, you might wish to create other
       clusters for testing, with other superusers, a cluster for each user on
       a shared server, etc. pg_createcluster will abort with an error if you
       try to create a cluster with a name that already exists for that
       version.

       For compatibility with systemd service units, the cluster name should
       not contain any dashes (-). pg_ctlcluster will warn about the problem,
       but succeed with the operation.

       Given a major PostgreSQL version (like "8.2" or "8.3") and a cluster
       name, it creates the necessary configuration files in
       /etc/postgresql/version/name/; in particular these are postgresql.conf,
       pg_ident.conf, pg_hba.conf, a postgresql-common specific configuration
       file start.conf (see STARTUP CONTROL below), pg_ctl.conf, and a
       symbolic link log which points to the log file (by default,
       /var/log/postgresql/postgresql-version-name.log).

       postgresql.conf is automatically adapted to use the next available
       port, i.  e. the first port (starting from 5432) which is not yet used
       by an already existing cluster.

       If the data directory does not yet exist, PostgreSQL's initdb(1)
       command is used to generate a new cluster structure. If the data
       directory already exists, it is integrated into the postgresql-common
       structure by moving the configuration file and setting the
       data_directory option. Please note that this only works for data
       directories which were created directly with initdb, i.  e. all the
       configuration files (postgresql.conf etc.) must be present in the data
       directory.

       If a custom socket directory is given and it does not exist, it is
       created.

       If the log file does not exist, it is created. In any case the
       permissions are adjusted to allow write access to the cluster owner.
       Please note that postgresql.conf can be customized to specify
       log_directory and/or log_filename; if at least one of these options is
       present, then the symbolic link log in the cluster configuration
       directory is ignored.

       If the default snakeoil SSL certificate exists
       (/etc/ssl/certs/ssl-cert-snakeoil.pem and
       /etc/ssl/private/ssl-cert-snakeoil.key), and the postgres user is in
       the ssl-cert Unix group, pg_createcluster configures the cluster to use
       this certificate, and enables SSL. Therefore all clusters will use the
       same SSL certificate by default. For versions up to 9.1, symlinks in
       the data directory will be created (server.crt and server.key); for 9.2
       and later, the appropriate postgresql.conf options will be set
       (ssl_cert_file and ssl_key_file). Of course you can replace this with a
       cluster specific certificate. Similarly for
       /etc/postgresql-common/root.crt and /etc/postgresql-common/root.crl,
       these files will be configured as client certificate CA and revocation
       list, when present. (root.crt is initially a placeholder that will only
       be used if real certificates are added to the file.)

OPTIONS
       -u user, --user=user
           Set the user who owns the cluster and becomes the database
           superuser to the given name or uid.  By default, this is the user
           postgres.  A cluster must not be owned by root.

       -g group, --group=group
           Change the group of the cluster related data files. By default this
           will be the primary group of the database owner.

       -d dir, --datadir=dir
           Explicitly set the data directory path, which is used to store all
           the actual databases and tables. This will become quite big (easily
           in the order of five times the amount of actual data stored in the
           cluster). Defaults to /var/lib/postgresql/version/cluster.

       -s dir, --socketdir=dir
           Explicitly set the directory where the postgres(1) server stores
           the Unix socket for local connections. Defaults to
           /var/run/postgresql/ for clusters owned by the user postgres, and
           /tmp for clusters owned by other users.  Please be aware that /tmp
           is an unsafe directory since everybody can create a socket there
           and impersonate the database server. If the given directory does
           not exist, it is created with appropriate permissions.

       -l path, --logfile=path
           Explicitly set the path for the postgres(1) server log file.
           Defaults to /var/log/postgresql/postgresql-version-cluster.log.

       --locale=locale
           Set the default locale for the database cluster. If this option is
           not specified, the locale is inherited from the environment that
           pg_createcluster runs in.

       --lc-collate=locale
       --lc-ctype=locale
       --lc-messages=locale
       --lc-monetary=locale
       --lc-numeric=locale
       --lc-time=locale
           Like --locale, but only sets the locale in the specified category.

       -e encoding, --encoding=encoding
           Select the encoding of the template database. This will also be the
           default encoding of any database you create later, unless you
           override it there. The default is derived from the locale, or
           SQL_ASCII if that does not work.  The character sets supported by
           the PostgreSQL server are described in the documentation.

           Note: It is not recommended to set this option directly! Set the
           locale instead.

       -p port, --port=port
           Select the port the new cluster listens on (for the Unix socket and
           the TCP port); this must be a number between 1024 and 65535, since
           PostgreSQL does not run as root and thus needs an unprivileged port
           number. By default the next free port starting from 5432 is
           assigned.

       --start
           Immediately start a server for the cluster after creating it (i. e.
           call pg_ctlcluster version cluster start on it). By default, the
           cluster is not started.

       --start-conf=auto|manual|disabled
           Set the initial value in the start.conf configuration file. See
           STARTUP CONTROL below. By default, auto is used, which means that
           the cluster is handled by /etc/init.d/postgresql, i. e. starts and
           stops automatically on system boot.

       -o guc=value, --pgoption guc=value
           Configuration option to set in the new postgresql.conf file.

       --createclusterconf=file
           Alternative createcluster.conf file to use. Default is
           /etc/postgresql-common/createcluster.conf (or
           $PGSYSCONFDIR/createcluster.conf).

       --environment=file
           Alternative default environment file to use. Default is
           /etc/postgresql-common/environment (or $PGSYSCONFDIR/environment).
           If the file is missing, a placeholder string is used.  %v and %c
           are replaced; see DEFAULT VALUES below.

       -- initdb options
           Options passed directly to initdb(1).

           Per default, pg_createcluster will update the pg_hba.conf file
           generated by initdb to use peer authentication on local (unix)
           connections, and md5 on TCP (host) connections. If explicit
           authentication config is included here (-A, --auth, --auth-host,
           --auth-local), the pg_hba.conf file will be left untouched.

STARTUP CONTROL
       The start.conf file in the cluster configuration directory controls the
       start/stop behavior of that cluster's postgres process. The file can
       contain comment lines (started with '#'), empty lines, and must have
       exactly one line with one of the following keywords:

       auto
           The postgres process is started/stopped automatically in the init
           script.

           When running from systemd, the cluster is started/stopped when
           postgresql.service is started/stopped.  This is also the default if
           the file is missing.

       manual
           The postgres process is not handled by the init script, but
           manually controlling the cluster with pg_ctlcluster(1) is
           permitted.

           When running from systemd, the cluster is not started automatically
           when postgresql.service is started. However, stopping/restarting
           postgresql.service will stop/restart the cluster. The cluster can
           be started using systemctl start postgresql@version-cluster.

       disabled
           Neither the init script, pg_ctlcluster(1), nor postgresql@.service
           are permitted to start/stop the cluster. Please be aware that this
           will not stop the cluster owner from calling lower level tools to
           control the postgres process; this option is only meant to prevent
           accidents during maintenance, not more.

       When running from systemd, invoke systemctl daemon-reload after editing
       start.conf.

       The pg_ctl.conf file in the cluster configuration directory can contain
       additional options passed to pg_ctl of that cluster.

DEFAULT VALUES
       Some default values used by pg_createcluster can be modified in
       /etc/postgresql-common/createcluster.conf. Occurrences of %v are
       replaced by the major version number, and %c by the cluster name. Use
       %% for a literal %.

       create_main_cluster (Default: true)
           Create a main cluster when a new postgresql-x.y server package is
           installed.

       start_conf (Default: auto)
           Default start.conf value to use.

       data_directory (Default: /var/lib/postgresql/%v/%c)
           Default data directory.

       waldir|xlogdir (Default: unset)
           Default directory for transaction logs. When used, initdb will
           create a symlink from pg_wal (PostgreSQL 9.6 and earlier: pg_xlog)
           in the data directory to this location. Unset by default, i.e.
           transaction logs remain in the data directory. Both spellings of
           this option are accepted, and translated to the correct initdb
           invocation depending on the cluster version.

       initdb_options (Default: unset)
           Other options to pass to initdb.

       Other options
           All other options listed are copied into the new cluster's
           postgresql.conf, e.g.:

               listen_addresses = '*'
               log_line_prefix = '%%t '

           Some postgresql.conf options are treated specially:

           ssl Only added to postgresql.conf if the default snakeoil
               certificates exist and are readable for the cluster owner as
               detailed above.

           stats_temp_directory
               Only added to postgresql.conf if existing, and writable for the
               cluster owner, or else if the parent directory is writable.

       Include files
           include
           include_if_exists
           include_dir
               createcluster.conf supports the same include directives as
               postgresql.conf.

           add_include
           add_include_if_exists
           add_include_dir
               To add include directives to the new postgresql.conf file, use
               the add_* directives. The add_ prefix is removed.

SEE ALSO
       initdb(1), pg_ctlcluster(8), pg_lsclusters(1), pg_wrapper(1)

AUTHORS
       Martin Pitt <mpitt@debian.org>, Christoph Berg <myon@debian.org>

Debian                            2017-12-15               PG_CREATECLUSTER(1)
#+end_example

* The main database 

There is one DB that makes up what the ~CRUD~ is for. 

#+BEGIN_SRC sql
CREATE DATABASE ecm_dev OWNER ecm;
#+END_SRC

* Upgrading
  
** 9.4.14 -> 10.1

Make a backup

#+BEGIN_SRC shell
sudo -u postgres pg_basebackup --host=ecm.maxwellclaims.net --port=5432 --pgdata=/ecm/db/9.4/ --user=maxclaims
#+END_SRC

Remove the WALs.

#+BEGIN_SRC shell
sudo rm /ecm/db/9.4/pg_xlog/*
#+END_SRC

Create a cluster

#+BEGIN_SRC shell
sudo apt-get install postgresql-9.4

sudo pg_createcluster --user=postgres --group=postgres \
    --socketdir=/var/run/postgresql \
    --locale=en_CA.UTF-8 --port 5443 9.4 backup
#+END_SRC

Stop the actual application, force the WAL's out, and shut down the
main master.

#+BEGIN_SRC sql
select pg_switch_xlog();
#+END_SRC

#+BEGIN_SRC shell
sudo service postgresql@9.4-main stop
#+END_SRC

Copy the WAL's over using rsync

#+BEGIN_SRC shell
sudo -u postgresql mkdir -p /ecm/db/9.4/WAL
sudo -u postgres rsync -avz --rsync-path='sudo rsync' ecm@ecm.maxwellclaims.net:/ecm/db/master/WAL/  /ecm/db/9.4/WAL/
#+END_SRC

remove/copy the cluster's data

#+BEGIN_SRC shell
sudo rm -rf /var/lib/postgresql/9.4/backup/*
cp -a /ecm/db/9.4/* /var/lib/postgresql/9.4/backup/
#+END_SRC

Create a recovery.conf to recover it.
#  :tangle  "../etc/postgresql/upgrade-recovery.conf"
#+BEGIN_SRC conf
restore_command = 'cp /ecm/db/9.4/WAL/%f "%p"'
#+END_SRC

#+BEGIN_SRC shell
sudo chown postgres 9.4/recovery.conf
#+END_SRC

Start up the new server.

#+BEGIN_SRC shell
sudo pg_ctlcluster 9.4 backup start
#+END_SRC


Create the new 10 cluster

#+BEGIN_SRC shell
sudo apt-get install postgresql-10

sudo pg_createcluster --user=postgres --group=postgres \
    --socketdir=/var/run/postgresql \
    --locale=en_CA.UTF-8 --port 5433 10 master

sudo pg_ctlcluster 10 master start 
#+END_SRC

Use it to dump/restore

#+BEGIN_SRC shell
  pg_dumpall --host localhost --port=5432 --lock-wait-timeout=0 \
	     --user=maxclaims --database=maxclaims \
        --clean \
        --quote-all-identifiers \
      | time -v sudo -u ecm psql --port=5433 --dbname=postgres 
#+END_SRC
*** to_regclass

#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION to_regclass(anyelement)
 RETURNS regclass LANGUAGE SQL AS $$ 
   SELECT to_regclass($1::text) ;
$$;

#+END_SRC

#+RESULTS:
| CREATE FUNCTION |
|-----------------|

 #+BEGIN_SRC sql :results code :exports none
 select pg_get_functiondef(oid)
 from pg_proc
 where proname = 'describe_pkey';
 #+END_SRC

 #+BEGIN_SRC sql
 CREATE OR REPLACE FUNCTION pongo.describe_pkey(anyelement)
  RETURNS json
  LANGUAGE sql
 AS $function$
 -- => json array of {"name":"","type":""} objects
 -- Tell us what the pkeys columns are, and their types.
 SELECT json_agg(pkeys)
  FROM (SELECT a.attname AS name, format_type(a.atttypid, a.atttypmod) AS type
	  FROM   pg_index i
	  JOIN   pg_attribute a ON a.attrelid = i.indrelid
			     AND a.attnum = ANY(i.indkey)
	  WHERE  i.indrelid = to_regclass(pg_typeof($1)::text::cstring)
	  AND    i.indisprimary) AS pkeys;

 $function$

 #+END_SRC

 #+RESULTS:
 | CREATE FUNCTION |
 |-----------------|



*** misc 
#+BEGIN_SRC sql :engine postgresql :cmdline "--port 5432 --host ecm.maxwellclaims.net --user maxclaims maxclaims" 
SELECT version();
#+END_SRC

#+BEGIN_SRC sql :engine postgresql :cmdline "--port 5433 --host athena.maxwellclaims.net --user maxclaims maxclaims" 
SELECT version();
#+END_SRC

#+RESULTS:
| version                                                                                                        |
|----------------------------------------------------------------------------------------------------------------|
| PostgreSQL 10.1 on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609, 64-bit |

#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION public.to_regclass(cstring)
 RETURNS pg_catalog.regclass LANGUAGE SQL AS $$
  SELECT pg_catalog.to_regclass($1::text) ;
$$;

#+END_SRC
* Dumping and restoring
  
#+RESULTS:

#+BEGIN_SRC sh
  pg_dumpall --host cora.maxwellclaims.net --lock-wait-timeout=0 \
	     --user=maxclaims --database=maxclaims \
      | sudo -u ecm psql --port=5442 --dbname=postgres

#+END_SRC


#+BEGIN_SRC sh
  pg_dumpall --host cora.maxwellclaims.net --lock-wait-timeout=0 \
	     --user=maxclaims --database=maxclaims \
        --clean \
        --quote-all-identifiers \
      | sudo -u ecm psql --port=5433 --dbname=postgres 

#+END_SRC


** TODO Dump the maxclaims database only

This expect the maxclaims database to be dropped first due to the
~--create~. We use ~--quote-all-identifiers~ because we may be
switching Postgresql Versions.

#+BEGIN_SRC sh
  pg_dump --host ecm.maxwellclaims.net --lock-wait-timeout=0 \
	  --user=maxclaims --dbname=maxclaims \
	  --create --quote-all-identifiers \
	  --file=maxclaims-db.sql

#+END_SRC

*** claim transactions only
#+BEGIN_SRC sh
  pg_dump --host=localhost --port=5433 --lock-wait-timeout=0 \
	  --user=maxclaims --dbname=maxclaims \
	  --clean --quote-all-identifiers --table=claim_transaction\
	  --file=maxclaims-claim_transaction.sql

#+END_SRC
